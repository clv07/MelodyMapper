################################################################################
# Filename: conversion.py
# Purpose:  Perform audio processing and conversion tasks to MIDI.
# Author:   Livia Chandra, Roshni Venkat and Darren Seubert
#
# Description:
# This file contains functions for audio processing tasks, including conversion
# of audio files to MIDI format. It includes helper functions for audio file
# conversion to WAV file, frequency segmentation, and MIDI file generation.
#
# Usage (Optional):
# User can use the provided functions to convert audio files to MIDI format.
# Ensure that the required dependencies, such as pydub, librosa, numpy, scipy,
# and mido, are installed in user's Python environment.
#
# Notes:
# - This file supports audio files in the format of MP3, M4A, WAV and WEBM.
# - Ensure that the audio files contain a single melody line for more
#   accurate MIDI conversion.
# - The MIDI files generated by this file will contain MIDI note messages
#   corresponding to the detected pitch and rhythm of the input audio.
#
###############################################################################

import io
import os
import subprocess
import pydub
import librosa
import numpy as np
import scipy.signal as signal
import math
import mido

# Path to where midi file is being stored
midi_folder = "midi_output"


def convert_webm_to_mp3(webm_file, mp3_file):
    """
    Helper function to convert WEBM file into MP3 file.

    Args:
        webm_file (string): The path to obtain WEBM file.
    """

    # Command to convert the WEBM file to MP3
    command = [
        "ffmpeg",
        "-i",
        webm_file,
        "-vn",
        "-ab",
        "192k",
        "-ar",
        "44100",
        "-y",
        mp3_file,
    ]

    # Run the command through the subprocess module
    try:
        result = subprocess.run(command, check=True)
    except subprocess.CalledProcessError as e:
        print("An error occurred during audio file conversion:", e)


def audio_to_wav(audio_file):
    """
    Helper function to convert audio file into WAV file for MIDI conversion.

    Args:
        audio_file (string): The path to obtain audio file.

    Returns:
        file_name (string): File name to name converted MIDI file.
        wav_file (string): The path to obtain audio file with wav extension.
    """
    # List of accepted audio file type
    available_extension = ["m4a", "mp3", "wav", "webm"]

    # Get the name and the extension type of the input audio file
    file_name, extension = os.path.splitext(audio_file)
    file_name = file_name.split("/")[-1]

    # Check the extension of the input audio file
    try:
        if extension[1:] not in available_extension:
            raise ValueError("Extension not available")
    except ValueError as e:
        print("An error occurred during audio file conversion:", e)
        return None

    # Get current directory
    current_directory = os.getcwd()

    # Convert WEBM file to MP3 file
    if extension[1:] == "webm":
        mp3_file_path = os.path.join(current_directory, file_name + ".mp3")
        convert_webm_to_mp3(audio_file, mp3_file_path)
        audio_file = mp3_file_path
        _, extension = os.path.splitext(audio_file)

    # Convert MP3 and M4A file to WAV file
    wav_file_path = os.path.join(current_directory, file_name + ".wav")
    wav_file = pydub.AudioSegment.from_file(audio_file, extension[1:]).export(
        wav_file_path, format="wav"
    )

    return file_name, wav_file


def divide_audio_data(audio_data, sample_rate, tempo):
    """
    Helper function to divide array into segments with variable length based on BPM.

    Args:
        audio_data (ndarray): 1D array that contains audio signal information
        sample_rate (int): Number of samples per second (Hz) used when loading the
                           audio file.
        tempo (float64): Estimated tempo of the audio signal in beats per minute (BPM)

    Yields:
        ndarray: Segments of audio data with variable length based on the BPM.
    """
    try:
        # Calculate the duration of one beat in seconds
        beat_duration = 60 / tempo

        # Calculate the desired length of each segment based on the beat duration
        desired_len = int(sample_rate * beat_duration * 2)

        # Loop through the array and yield segments of the desired length
        for i in range(0, len(audio_data), desired_len):
            yield audio_data[i : i + desired_len]
    except Exception as e:
        print("An error occurred during audio data division:", e)
        return None


def wav_to_midi(audio_file):
    """
    Convert audio file to MIDI format.

    Args:
        audio_file (str): The path to the audio file.

    Returns:
        str: The path to the generated MIDI file.
    """

    # Convert audio file into WAV file
    file_name, wav_file = audio_to_wav(audio_file)

    # Load audio file using librosa
    audio_data, sample_rate = librosa.load(wav_file)

    # Set min and max frequencies for pitch detection
    fmin = librosa.note_to_hz("C1")
    fmax = librosa.note_to_hz("C8")

    # Perform pitch detection to identify dominant pitch
    pitch = librosa.yin(y=audio_data, sr=sample_rate, fmin=fmin, fmax=fmax)

    # Find the most frequent pitch
    dominant_pitch = np.argmax(pitch)

    # Determine key signature by mapping MIDI note number
    key_map = {
        0: "C",
        1: "C#",
        2: "D",
        3: "D#",
        4: "E",
        5: "F",
        6: "F#",
        7: "G",
        8: "G#",
        9: "A",
        10: "A#",
        11: "B",
    }
    key_signature = key_map[int(dominant_pitch) % 12]

    # Obtain BPM
    tempo, beat_frames = librosa.beat.beat_track(y=audio_data, sr=sample_rate)

    # Obtain time
    beat_times = librosa.frames_to_time(beat_frames, sr=sample_rate)

    # Divide audio into segments with variable length based on BPM
    trimmed_frequency = list(divide_audio_data(audio_data, sample_rate, tempo))

    # STFT Parameters
    window_size = 512  # Window size
    hop_length = 128  # Hop length

    # Analyze frequency for each time frame
    frequency_list = []

    # Compute STFT for each segment
    for frequency in trimmed_frequency:

        # Adjust nperseg and noverlap based on the length of the segment
        nperseg = min(len(frequency), window_size)
        noverlap = nperseg - hop_length
        _, _, stft = signal.stft(
            frequency, fs=sample_rate, nperseg=nperseg, noverlap=noverlap
        )

        # Sum across time axis to get magnitude spectrum
        magnitude_spectrum = np.abs(stft).mean(axis=1)

        # Convert to frequency domain
        frequency_bins = np.fft.fftfreq(len(magnitude_spectrum)) * sample_rate

        # Weighted median frequency
        median_freq_index = np.argmax(
            np.cumsum(magnitude_spectrum) >= np.sum(magnitude_spectrum) / 2
        )
        median_freq = frequency_bins[median_freq_index]

        frequency_list.append(median_freq)

    # Filter out invalid frequencies
    filtered_frequency_list = [freq for freq in frequency_list if freq > 0]

    # Set the velocity to determine the volume of output midi file
    velocity = 127

    # Calculate MIDI notes
    midi_note = [
        (int(12 * math.log(freq / 440.0) / math.log(2)) + 69)
        for freq in filtered_frequency_list
    ]

    # Create a new MIDI file and track
    midi = mido.MidiFile()
    track = mido.MidiTrack()
    midi.tracks.append(track)

    # Set the key signature meta message
    key_sig_message = mido.MetaMessage("key_signature", key=key_signature, time=0)
    track.append(key_sig_message)

    # Create and append the tempo meta message in microseconds
    tempo_microseconds = int(60 * 10**6 / tempo)
    tempo_message = mido.MetaMessage("set_tempo", tempo=tempo_microseconds)
    track.append(tempo_message)

    # Calculate MIDI time based on tempo
    midi_time = [
        (beat_times[i] - beat_times[i - 1]) * 60 / tempo
        for i in range(1, len(beat_times))
    ]

    # Reverse the time list
    midi_new_time = list(reversed(midi_time))

    # Create MIDI messages
    for note, time in zip(midi_note, midi_new_time):

        # Convert time from seconds to ticks
        ticks_per_beat = midi.ticks_per_beat
        time_ticks = int(round(time * sample_rate / (60 * tempo / ticks_per_beat)))

        # Write MIDI message and append to the MIDI track
        if note > 0:
            message_on = mido.Message(
                "note_on", note=note, velocity=velocity, time=time_ticks
            )
            message_off = mido.Message(
                "note_off", note=note, velocity=velocity, time=time_ticks
            )
            track.append(message_on)
            track.append(message_off)

    # Save MIDI file
    midi_file_name = os.path.join(midi_folder, file_name + ".mid")
    midi.save(midi_file_name)

    return midi_file_name
